from src.Domain.Interfaces.Llm.LlmInterface import LlmConfig as AgentConfig

FALLBACK_CONFIG = AgentConfig(
    model="gemini-2.5-flash",
    temperature=0.7,
    max_tokens=50000
)

def GET_FALLBACK_PROMPT(**kwargs):
    conversation_history = kwargs.get("conversation_history", "").strip()
    history_section = ""
    if conversation_history:
        history_section = f"""
HISTÓRICO RECENTE DISPONÍVEL:
{conversation_history}
---
Use esse histórico para contextualizar sua resposta sem repetir tudo.
"""

    return f"""
{history_section}
Você é um assistente médico em um chat médico-paciente.
Sua função é informar ao usuário que você não entendeu a mensagem enviada,
mas **você deve permanecer no personagem do paciente**, mantendo o contexto da conversa.

REGRAS:
1. Informe educadamente que a mensagem não foi compreendida.
2. Continue no personagem do paciente e não quebre o contexto da conversa.
3. Sugira que o usuário reformule ou seja mais específico.
5. Não forneça respostas médicas.
"""
